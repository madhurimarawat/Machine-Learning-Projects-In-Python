{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e746be",
   "metadata": {},
   "source": [
    "## CIFAR-10 Dataset Overview\n",
    "\n",
    "CIFAR stands for \"Canadian Institute for Advanced Research\".The CIFAR-10 dataset is a widely used dataset in the field of computer vision and machine learning. It consists of 60,000 32x32 color images, divided into 10 classes, with each class containing 6,000 images. This dataset is commonly used for image classification tasks and serves as a benchmark for evaluating machine learning and deep learning models.\n",
    "\n",
    "### Classes\n",
    "\n",
    "The dataset is categorized into the following 10 classes:\n",
    "\n",
    "1. Airplane\n",
    "2. Automobile\n",
    "3. Bird\n",
    "4. Cat\n",
    "5. Deer\n",
    "6. Dog\n",
    "7. Frog\n",
    "8. Horse\n",
    "9. Ship\n",
    "10. Truck\n",
    "\n",
    "### Dataset Split\n",
    "\n",
    "- Training Set: 50,000 images\n",
    "- Test Set: 10,000 images\n",
    "\n",
    "### Image Dimensions\n",
    "\n",
    "- Each image is 32 pixels in width and 32 pixels in height.\n",
    "- Images are in color, with three channels (red, green, and blue).\n",
    "\n",
    "### Usage\n",
    "\n",
    "Researchers and practitioners often use the CIFAR-10 dataset to develop and evaluate image classification algorithms. It's a relatively small dataset, making it suitable for experimentation and prototyping.\n",
    "\n",
    "In this notebook, I will apply neural networks to perform image classification on this dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d368621",
   "metadata": {},
   "source": [
    "## Keras Overview\n",
    "\n",
    "Keras is an open-source, high-level neural networks API written in Python. It is designed for ease of use and rapid prototyping of deep learning models. Keras acts as an interface to other deep learning frameworks, including TensorFlow, Theano, and Microsoft Cognitive Toolkit (CNTK).\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **User-Friendly:** Keras provides a simple and intuitive API that makes it easy for beginners to get started with deep learning.\n",
    "- **Modular and Extensible:** It allows you to build neural networks by stacking layers, making it highly modular and customizable.\n",
    "- **Support for Multiple Backends:** Keras can seamlessly switch between different backend engines, with TensorFlow being the default choice.\n",
    "- **Community and Ecosystem:** There is a large community of users and developers, resulting in a rich ecosystem of pre-trained models and extensions.\n",
    "- **Integration:** It can be integrated into larger machine learning workflows and supports both CPU and GPU acceleration.\n",
    "\n",
    "For more information and documentation, visit the [Keras website](https://keras.io/).\n",
    "\n",
    "\n",
    "## TensorFlow Overview\n",
    "\n",
    "TensorFlow is an open-source machine learning framework developed by Google. It is widely used for a variety of machine learning and deep learning tasks, including neural networks, natural language processing, and computer vision.\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Flexibility:** TensorFlow offers a versatile platform for developing and deploying machine learning models, including neural networks.\n",
    "- **Scalability:** It supports distributed computing and is designed to scale from a single device to large clusters of machines.\n",
    "- **High-Performance:** TensorFlow provides GPU and TPU acceleration for training deep learning models, resulting in faster computations.\n",
    "- **Rich Ecosystem:** TensorFlow has a rich ecosystem of libraries and tools, including TensorFlow Extended (TFX), TensorBoard for visualization, and TensorFlow Lite for mobile and embedded devices.\n",
    "- **Integration:** TensorFlow can be integrated with other popular libraries and frameworks, such as Keras.\n",
    "\n",
    "### TensorFlow 2.x\n",
    "\n",
    "TensorFlow 2.x introduced significant improvements in terms of ease of use and integration with Keras. It made building and training deep learning models more user-friendly and efficient.\n",
    "\n",
    "For more information and documentation, visit the [TensorFlow website](https://www.tensorflow.org/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67827ca",
   "metadata": {},
   "source": [
    "## Neural Network Overview\n",
    "\n",
    "A neural network is a computational model inspired by the structure and functioning of the human brain. It is a fundamental building block in modern machine learning and artificial intelligence. Neural networks consist of interconnected nodes, called neurons, organized into layers. These networks are designed to process and learn from data, making them particularly powerful for tasks like image recognition, natural language processing, and more.\n",
    "\n",
    "### Key Components\n",
    "\n",
    "- **Neurons:** Neurons are the basic processing units in a neural network. They receive inputs, apply a transformation (usually involving weights and activation functions), and produce outputs.\n",
    "\n",
    "- **Layers:** Neurons are organized into layers, including input layers, hidden layers, and output layers. The connections between neurons carry information and weights that are adjusted during training.\n",
    "\n",
    "- **Weights:** Each connection between neurons has an associated weight. These weights determine the strength of the connection and are adjusted during training to improve the network's performance.\n",
    "\n",
    "- **Activation Functions:** Activation functions introduce non-linearity into the neural network, allowing it to model complex relationships in data. Common activation functions include ReLU (Rectified Linear Unit), sigmoid, and tanh.\n",
    "\n",
    "### Training Process\n",
    "\n",
    "Neural networks learn from data through a process called training. During training, the network is exposed to a dataset, and it adjusts its weights to minimize a defined loss function. Common optimization algorithms like stochastic gradient descent (SGD) are used to update weights iteratively.\n",
    "\n",
    "### Deep Learning\n",
    "\n",
    "Deep learning is a subfield of machine learning that focuses on deep neural networks with multiple hidden layers. These deep neural networks, often referred to as deep learning models, have achieved state-of-the-art results in various domains, including computer vision, natural language processing, and speech recognition.\n",
    "\n",
    "### Applications\n",
    "\n",
    "Neural networks and deep learning have applications in diverse areas, such as image classification, object detection, sentiment analysis, recommendation systems, autonomous vehicles, and medical diagnosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44ad5a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Required Libraries\n",
    "\n",
    "# Importing TensorFlow which is a deep learning framework, for building and training neural networks.\n",
    "import tensorflow as tf\n",
    "\n",
    "# Importing Keras, a high-level API for building neural networks, which is integrated into TensorFlow.\n",
    "from tensorflow import keras\n",
    "\n",
    "# Importing layers from Keras to define the layers of the neural network architecture.\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd98b80",
   "metadata": {},
   "source": [
    "##  Data Gathering\n",
    "\n",
    "Importing the cifar10 dataset\n",
    "\n",
    "### Data Preprocessing\n",
    "\n",
    "The `255.0` is used as a floating-point number to perform a division operation on the pixel values in the `x_train` and `x_test` datasets. It's used to normalize the pixel values to a range between 0 and 1.\n",
    "\n",
    "In image data, pixel values are typically represented as integers in the range [0, 255]. By dividing each pixel value by `255.0`, you are scaling them down to a floating-point range between 0 and 1. This scaling is a common preprocessing step in deep learning for image data, as it ensures that the pixel values are within a suitable range for neural network training, where floating-point numbers are often used for numerical stability and consistent scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28ef2e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the CIFAR-10 dataset\n",
    "# The training and testing data is already defined in keras\n",
    "# We just need to import it\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to [0, 1] for numerical stability in deep learning.\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283474a5",
   "metadata": {},
   "source": [
    "## Defining neural network architecture:\n",
    "\n",
    "### Convolutional neural network (CNN):\n",
    "\n",
    "- **Convolutional Layers:** Convolutional layers in CNNs apply filters to input data to automatically extract features, such as edges and textures, from images.\n",
    "  \n",
    "- **Pooling Layers:** Pooling layers reduce spatial dimensions and downsample feature maps, improving computational efficiency and focusing on essential features.\n",
    "  \n",
    "- **Effective for Computer Vision:** CNNs are highly effective in computer vision tasks, such as image classification, object detection, and facial recognition, thanks to their ability to learn hierarchical features from visual data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8216dbd2",
   "metadata": {},
   "source": [
    "## Explanation of the code\n",
    "\n",
    "```python\n",
    "model = keras.Sequential([\n",
    "```\n",
    "\n",
    "- This line initializes a Sequential model in Keras. A Sequential model is a linear stack of layers, and you can add layers to it one by one.\n",
    "\n",
    "```python\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "```\n",
    "\n",
    "- This line adds a 2D convolutional layer to the model. It has 32 filters (also known as kernels) of size 3x3. The activation function used is ReLU (Rectified Linear Unit), which introduces non-linearity to the model. The `input_shape` parameter specifies that the expected input data should have a shape of (32, 32, 3), where 32x32 is the image size, and 3 represents the number of color channels (red, green, and blue).\n",
    "\n",
    "```python\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "```\n",
    "\n",
    "- This line adds a max-pooling layer to the model. Max-pooling reduces the spatial dimensions of the feature map by taking the maximum value in each 2x2 region. It is often used to downsample the data and reduce computation.\n",
    "\n",
    "```python\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "```\n",
    "\n",
    "- This line adds another convolutional layer with 64 filters and a 3x3 filter size. The ReLU activation function is used again.\n",
    "\n",
    "```python\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "```\n",
    "\n",
    "- Another max-pooling layer is added, further downsampling the feature map.\n",
    "\n",
    "```python\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "```\n",
    "\n",
    "- This line adds a third convolutional layer with 64 filters and a 3x3 filter size, also using the ReLU activation function.\n",
    "\n",
    "```python\n",
    "    layers.Flatten(),\n",
    "```\n",
    "\n",
    "- This line adds a Flatten layer to the model. It's used to flatten the 2D feature maps into a 1D vector. This is necessary before transitioning from convolutional layers to fully connected layers.\n",
    "\n",
    "```python\n",
    "    layers.Dense(64, activation='relu'),\n",
    "```\n",
    "\n",
    "- This line adds a fully connected (dense) layer with 64 units and a ReLU activation function.\n",
    "\n",
    "```python\n",
    "    layers.Dense(10)  # 10 output classes for CIFAR-10\n",
    "])\n",
    "```\n",
    "\n",
    "- Finally, a second fully connected layer is added with 10 units, which corresponds to the 10 output classes for the CIFAR-10 dataset. There is no activation function specified for this layer, which means it will output raw scores or logits, typically used in multi-class classification problems.\n",
    "\n",
    "In summary, this code defines a convolutional neural network (CNN) model for image classification, specifically designed for the CIFAR-10 dataset, which contains 32x32 pixel images with 10 different classes. The model consists of convolutional layers, max-pooling layers, and fully connected layers to learn and classify patterns in the input images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8c87ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a CNN model for data\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10)  # 10 output classes for CIFAR-10\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a411444",
   "metadata": {},
   "source": [
    "## Explanation of the Code\n",
    "\n",
    "```python\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "- `model.compile()` is a method in Keras used to configure the training process of the model. <br><br>\n",
    "\n",
    "- `optimizer='adam'`: Here, we specify the optimizer for training the model. In this case, it's using the Adam optimizer, which is a popular optimization algorithm for training deep neural networks. Adam adapts the learning rates for each parameter during training to improve convergence.<br><br>\n",
    "\n",
    "- `loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)`: This line specifies the loss function to be used during training. The loss function is a measure of how well the model is performing. In this case, it's using `SparseCategoricalCrossentropy`, which is appropriate for multi-class classification problems like CIFAR-10. <br><br>\n",
    "`from_logits=True` indicates that the model's output logits (raw scores) are used before applying a softmax activation. The loss function will internally apply the softmax activation to calculate the loss.<br><br>\n",
    "\n",
    "- `metrics=['accuracy']`: Here, we specify the evaluation metric(s) to monitor during training. In this case, we're using 'accuracy' as the metric, which measures the classification accuracy of the model on the training data. It's a commonly used metric for classification tasks, as it tells you what percentage of the training data is correctly classified by the model.<br><br>\n",
    "\n",
    "So, this code sets up the model for training with the Adam optimizer, using cross-entropy loss for multi-class classification, and monitoring accuracy as the training metric. Once compiled, the model is ready to be trained on the dataset using the specified configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5591492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "# We need to specify the loss function, optimizer, and metrics for training\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311c4d76",
   "metadata": {},
   "source": [
    "## Explanation of the Code\n",
    "\n",
    "```python\n",
    "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    "```\n",
    "\n",
    "- `model.fit()`: This method is used to train the model. It takes the following arguments:<br><br>\n",
    "  - `x_train`: This is the training data, typically a NumPy array or a TensorFlow tensor, containing the input features (in this case, the training images). <br><br>\n",
    "  - `y_train`: This is the target labels corresponding to the training data.<br><br>\n",
    "  - `epochs=10`: The `epochs` parameter specifies the number of times the model will iterate through the entire training dataset. In this case, the model will be trained for 10 epochs.<br><br>\n",
    "  - `validation_data=(x_test, y_test)`: This parameter allows you to specify a validation dataset to monitor the model's performance during training. Here, `x_test` contains the test images, and `y_test` contains the corresponding labels. The model's performance on this dataset will be evaluated after each epoch.<br><br>\n",
    "\n",
    "The `model.fit()` method will train the model using the specified training data, loss function, optimizer, and metrics. It will perform forward and backward passes, update the model's weights using the optimizer, and repeat this process for the specified number of epochs.<br><br>\n",
    "\n",
    "The training progress and metrics for each epoch will be recorded in the `history` object, which we can use later for plotting training curves or analyzing the model's performance. The history object typically contains information about training loss, training accuracy, validation loss, and validation accuracy for each epoch.<br><br>\n",
    "\n",
    "So, in summary, this line of code trains the model on the provided training data (`x_train` and `y_train`) for 10 epochs while monitoring its performance on the validation data (`x_test` and `y_test`). The training results and metrics are stored in the `history` object for further analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8378125d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 59s 36ms/step - loss: 1.5029 - accuracy: 0.4529 - val_loss: 1.2418 - val_accuracy: 0.5499\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 1.1365 - accuracy: 0.5986 - val_loss: 1.0366 - val_accuracy: 0.6383\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.9811 - accuracy: 0.6545 - val_loss: 0.9632 - val_accuracy: 0.6650\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.8777 - accuracy: 0.6928 - val_loss: 0.9513 - val_accuracy: 0.6759\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 57s 37ms/step - loss: 0.7993 - accuracy: 0.7213 - val_loss: 0.8987 - val_accuracy: 0.6857\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 57s 36ms/step - loss: 0.7348 - accuracy: 0.7434 - val_loss: 0.8983 - val_accuracy: 0.7015\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 57s 36ms/step - loss: 0.6848 - accuracy: 0.7604 - val_loss: 0.8407 - val_accuracy: 0.7125\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.6356 - accuracy: 0.7762 - val_loss: 0.8428 - val_accuracy: 0.7150\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.5930 - accuracy: 0.7923 - val_loss: 0.8506 - val_accuracy: 0.7178\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.5578 - accuracy: 0.8042 - val_loss: 0.9293 - val_accuracy: 0.6955\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddba6c6",
   "metadata": {},
   "source": [
    "## Explanation of the Code\n",
    "\n",
    "```python\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "```\n",
    "\n",
    "- `model.evaluate()`: This method is used to evaluate the model's performance on a dataset. It takes the following arguments: <br><br>\n",
    "  - `x_test`: This is the test data, typically a NumPy array or a TensorFlow tensor, containing the input features (in this case, the test images).<br><br>\n",
    "  - `y_test`: This is the target labels corresponding to the test data.<br><br>\n",
    "  - `verbose=2`: The `verbose` parameter controls the verbosity of the evaluation output. A value of `2` means that the evaluation will display progress bars for each batch of data during evaluation.<br><br>\n",
    "\n",
    "- `test_loss`: After evaluating the model, the test loss (a measure of how well the model performs on the test data) will be stored in the `test_loss` variable.<br><br>\n",
    "\n",
    "- `test_acc`: Similarly, the test accuracy (the classification accuracy of the model on the test data) will be stored in the `test_acc` variable.<br><br>\n",
    "\n",
    "So, this line of code computes the test loss and test accuracy of the trained model on the provided test data (`x_test` and `y_test`) and stores these values in the `test_loss` and `test_acc` variables, respectively. These values can be used to assess how well the model generalizes to new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dfc0729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 4s - loss: 0.9293 - accuracy: 0.6955 - 4s/epoch - 14ms/step\n",
      "Testing accuracy of the model is: 69.55000162124634\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"Testing accuracy of the model is: {test_acc*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39427a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
